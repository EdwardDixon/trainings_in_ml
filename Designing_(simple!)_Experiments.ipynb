{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Designing (simple!) Experiments.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdwardDixon/trainings_in_ml/blob/master/Designing_(simple!)_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "R5ZDXIerZ22z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Designing (simple!) Experiments\n",
        "\n",
        "How much data is enough? Was it a fluke?  For experimental results to be meaningful, we need to consider the role that chance may have played in our results.\n",
        "\n",
        "We'll study the problem by doing the classic experiment - flipping a simulated coin, to see how many times it comes up heads.  A fair coin would turn up \"heads\" on 50% of flips - but is this coin fair?  Let's leave the next code cell collapsed to keep a sense of mystery."
      ]
    },
    {
      "metadata": {
        "id": "WjjM7rv4aVOF",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from numpy.random import random \n",
        "\n",
        "def flip_dodgy_coin(weight = 0.65):\n",
        "    if random() > weight:\n",
        "        return 1\n",
        "    \n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOo2htN5am6D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How fair is my coin?\n",
        "The collapsed section above conceals a coin of \"unknown fairness\" (we don't know how often it comes up heads).  Let's start with a few tosses to observe its behavior..."
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "vfeGM27cZ221",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def experimental_flips(number_of_flips):\n",
        "    results = {'heads':0, 'tails':0}\n",
        "\n",
        "    for i in range(0, number_of_flips):\n",
        "        if flip_dodgy_coin() == 0:\n",
        "            results['heads'] += 1\n",
        "        else:\n",
        "            results['tails'] += 1\n",
        "\n",
        "    return(results)\n",
        "\n",
        "\n",
        "print(experimental_flips(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_lh_6triZ229",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What would the picture look like if we repeated our flips a lot more times?"
      ]
    },
    {
      "metadata": {
        "id": "LXVRoppuZ22-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def run_a_lot_of_experiments(how_many_batches = 1000, flips_per_batch=10):\n",
        "    results = []\n",
        "    \n",
        "    for i in range(0, how_many_batches):\n",
        "        batch_results = experimental_flips(flips_per_batch)\n",
        "        probability_heads = batch_results['heads'] / flips_per_batch\n",
        "        results.append(probability_heads)\n",
        "        \n",
        "    return (results)\n",
        "\n",
        "df_experiments = pd.DataFrame({'experiments':run_a_lot_of_experiments(1000, 10)})\n",
        "df_experiments.hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tLTiyQx8Z23D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see the there are a wide range of outcomes for this experiment - sometimes we are getting 9 heads from 10 flips, someone only 1 or 2.  Suspiciouly, the \"peak\" is not over 0.5!\n",
        "\n",
        "Since we are working with a proportion, the binomial theorem describes the distribution of our coin tosses.  We need to figure how variable our results will be with the number of samples we have. There is a simple formula for the \"standard error\" ($\\sigma_e$) of the sample:\n",
        "\n",
        "$$\\sigma_e = \\sqrt{\\frac{p(1-p)}{n}}$$\n",
        "\n",
        "- $p$ is the ratio of heads to total coin tosses that we observed\n",
        "- $n$ is the total number of tosses\n",
        "\n",
        "If we make $n$ bigger, we can see $\\sigma_e$ is going to get smaller.  We get big gains at first, but the $\\sqrt{}$ warns us the gains taper off..."
      ]
    },
    {
      "metadata": {
        "id": "XswU5SDTZ23E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "\n",
        "p = 0.5\n",
        "n_list = range(10,10000)\n",
        "\n",
        "def calculate_standard_error(p, n):\n",
        "    result = sqrt((p * (1-p)) / n)\n",
        "    return (result)\n",
        "\n",
        "sigma_e = []\n",
        "for n in n_list:\n",
        "    sigma_e.append(calculate_standard_error(p, n))\n",
        "    \n",
        "df = pd.DataFrame({'$\\sigma_e$' : sigma_e}, index=n_list)\n",
        "df.plot.line()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ts9O0rRZ23J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I think we probably all knew that n would be important, but the value of $p$ matters too:"
      ]
    },
    {
      "metadata": {
        "id": "K2TcnI4gZ23L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p_list = []\n",
        "p_one_minus_p = []\n",
        "for i in range(0,100):\n",
        "    p = i/100\n",
        "    p_list.append(p)\n",
        "    p_one_minus_p.append(p * (1-p))\n",
        "    \n",
        "df_p_important = pd.DataFrame({'$p*(1-p)$':p_one_minus_p}, index=p_list)\n",
        "df_p_important.plot.line()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8WvlzwpOZ23Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If we were working with a high value for $p$ - perhaps model accuracy? - we could actually get small error bars from a surprisingly small test set.  If the proportion is more towards the middle, we need more data to narrow the range of plausible values.\n",
        "\n",
        "So what is the range of likely values for our experiment?  We just need to multiply our standard error by a Z score - how sure do we want to be?\n",
        "\n",
        "![Z](https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/The_Normal_Distribution.svg/640px-The_Normal_Distribution.svg.png)\n",
        "\n",
        "If we take Z = 1.96, we get our 95% confidence interval:"
      ]
    },
    {
      "metadata": {
        "id": "L_PegfwFZ23R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = 0.5\n",
        "n = 100\n",
        "small_experiment = experimental_flips(n)\n",
        "p = small_experiment['heads'] / n\n",
        "\n",
        "standard_error = calculate_standard_error(p, n)\n",
        "error_margin = 1.65 * standard_error\n",
        "print('p(Heads) = %2.2f'%p + ' +- %2.2f'%error_margin + ' with 95% confidence')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WlX4qzmIZ23W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What if we wanted a specific confidence interval?  We already know our margin for error, $m$ is given by:\n",
        "\n",
        "$$m = Z\\sigma_e = Z\\sqrt{\\frac{p(1-p)}{n}} $$\n",
        "\n",
        "If we assume that we _know_ the margin we want, we can just re-arrange to find the number of samples that will give the 95% confidence interval a width of $2m$:\n",
        "\n",
        "$$n = 2\\frac{p(1-p)}{\\frac{m^2}{z^2}}$$"
      ]
    },
    {
      "metadata": {
        "id": "MITELlUzZ23X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z = 1.96\n",
        "m = 0.01\n",
        "samples_required = 2*(p * (1-p)) / (m*m/z*z)\n",
        "print(samples_required)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zIY-rp0pZ23c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "By returning to the experiment code, we can try our new value for sample size, and look at the histogram to see if our experiment works out like we calculated it should."
      ]
    },
    {
      "metadata": {
        "id": "nbF72G_dZ23d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}